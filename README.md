#  Detecci贸n de Fraude con Machine Learning

<p align="center">
  <img src="images/banner_fraude.png" width="700"/>
</p>


Este proyecto aplica t茅cnicas de **aprendizaje autom谩tico supervisado** para detectar transacciones fraudulentas en tarjetas de cr茅dito. El objetivo es construir un modelo eficaz que logre **identificar el fraude** minimizando los falsos negativos, en un contexto de **datos altamente desbalanceados**.

---

##  Dataset

- Dataset: [Credit Card Fraud Detection Dataset - Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- Observaciones: 284.807 transacciones
- Clases:
  - `0`: No fraude
  - `1`: Fraude (solo 0.17% del total)
- Variables: 30 (mayor铆a anonimizadas con PCA, m谩s `Time` y `Amount`)

---

##  T茅cnicas Utilizadas

- Exploraci贸n y limpieza de datos
- Submuestreo para balancear clases
- Visualizaciones con Seaborn y Matplotlib
- Entrenamiento con m煤ltiples modelos:
  - Regresi贸n Log铆stica
  - rbol de Decisi贸n
  - Random Forest
  - XGBoost
- Optimizaci贸n de hiperpar谩metros con `GridSearchCV`
- Creaci贸n de Pipelines con `sklearn.pipeline`
- Interpretabilidad con `SHAP`
- Evaluaci贸n en conjunto de prueba no balanceado

---

## 锔 Tecnolog铆as

- Python 3.x
- Jupyter Notebook
- Pandas, Numpy
- Scikit-learn
- XGBoost
- Matplotlib, Seaborn
- SHAP

---

##  Resultados

| Modelo               | F1-score (fraude) | ROC AUC  | Accuracy | Recall (fraude) |
|---------------------|------------------:|---------:|---------:|----------------:|
| **Random Forest**    | **0.0981**         | **0.9708** | 97.30%   | 0.8803          |
| XGBoost             | 0.0705            | 0.9707   | 96.13%   | 0.8803          |
| Regresi贸n Log铆stica | 0.0664            | 0.9630   | 95.87%   | 0.8803          |
| rbol de Decisi贸n   | 0.0343            | 0.9083   | 91.52%   | **0.9014**      |

>  **Conclusi贸n**: Todos los modelos lograron un buen recall para la clase fraudulenta, pero **Random Forest** fue el m谩s equilibrado y eficaz en t茅rminos de F1-score. XGBoost tambi茅n mostr贸 gran desempe帽o. La combinaci贸n de balanceo, pipeline y validaci贸n cruzada fue clave.

---

##  Visualizaciones

<img src="images/distribucion_clases.png" alt="Distribuci贸n de Clases" width="500"/>
<img src="images/distribucion_monto_clase.png" alt="Distribuci贸n de Monto seg煤n Clase" width="500"/>
<img src="images/boxplot_monto_clase.png" alt="Box Plot del Monto seg煤n Clase" width="500"/>
<img src="images/correlacion_variables_clase.png" alt="Correlaci贸n de variables con la clase objetivo" width="500"/>
<img src="images/roc_regresion.png" alt="Curva ROC - Regresi贸n Logistica (Pipeline)" width="500"/>
<img src="images/roc_arbol.png" alt="Curva ROC - rbol de decisi贸n (Pipeline)" width="500"/>
<img src="images/roc_randomforest.png" alt="Curva ROC - Random Forest (Pipeline)" width="500"/>
<img src="images/roc_xgboost.png" alt="Curva ROC - XGBoost (Pipeline)" width="500"/>

---

##  Interpretabilidad (SHAP)

Se utiliz贸 la librer铆a **SHAP** para explicar el modelo de XGBoost, identificando las variables que m谩s contribuyen a detectar fraudes.

 Importancia media de variables (SHAP)

<img src="images/shap_features_importance.png" alt="Feature Importance (mean SHAP value)" width="500"/>

 Distribuci贸n del impacto de las variables

<img src="images/shap_summary_plot.png" alt="SHAP summary plot" width="500"/>

 Explicaci贸n de una predicci贸n individual

<img src="images/shap_watterfall_plot.png" alt="SHAP waterfall plot" width="500"/>

---

##  Estructura del Repositorio

```markdown
fraude-tarjeta/
 fraude-tarjeta.ipynb         # Notebook con el proyecto completo
 README.md                    # Este archivo
 requeriments.txt             # Librer铆as necesarias
 /images                      # Gr谩ficos de EDA y resultados
麓麓麓

 Proyecto realizado por [Mat铆as Vallone](https://github.com/ValloneMatias)
